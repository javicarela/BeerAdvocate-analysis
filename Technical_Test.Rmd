---
title: "BeerAdvocate Data Analysis"
author: "Francisco Javier Carela Ferrer"
date: 'September 2023'
output:
  prettydoc::html_pretty:
    theme: architect    
    highlight: github
    toc: yes
    toc_depth: 3
---

<style type="text/css">
h1 {
  font-size: 30px;
}
h2 { /* Header 2 */
    font-size: 24px;
}
h3 { /* Header 3 */
    font-size: 20px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


To carry out this task, the free software R and the R Markdown editing tool will be used.

In this task, a dataset of 1.5 million beer reviews will be analyzed. The data set is available at the following link <https://data.world/socialmediadata/beeradvocate>. The data span a period of more than 10 years, including all ~1.5 million reviews up to November 2011. Each review includes ratings in terms of five "aspects": appearance, aroma, palate, taste, and overall impression. Reviews include product and user information, followed by each of these five ratings, and a plaintext review. We also have reviews from ratebeer.

# Preliminary analysis

First we load the require libraries: 
```{r, message=FALSE , warning=0}
library(data.table) # Handle large databases quickly
library(readr) # Load csv
library(DT) # Presentation of tables in RMarkdown
library(zoo) # Manipulation of dates, time series, ... etc.
library(Amelia) # Useful to work with NA data
library(ggplot2) # Graphical representation
library(psych) # Obtaining correlograms
```

In this first phase, the data is loaded for correct processing.
```{r, message=FALSE , warning=0}
beer_reviews <- read_csv("beer_reviews.csv")
beer_reviews<-data.table(beer_reviews)
```

We will use the *datatatable* library, which is useful when working with large databases in R, as in our case.

The dataset has 13 columns, which indicate:

- **brewery_id**: Identifier of the brewery manufacturer.

- **brewery_name**: Name of the beer manufacturer.

- **review_time**: Date of the review, expressed in seconds since January 1, 1970.  

- **review_overall**: Overall rating of the beer.

- **review_aroma**: Aroma rating.

- **review_appearance**: Appearance rating.

- **review_profilename**: Name of the user who made the review.

- **beer_style**: Beer style.

- **review_palate**: Palate rating.

- **review_taste**: Taste/flavor evaluation.

- **beer_name**: Beer name.

- **beer_abv**: % alcohol of the beer.

- **beer_beerid**: Beer identifier.


To obtain this information you can simply access a generic beerAdvocate page such as <https://www.beeradvocate.com/beer/profile/23222/78820/>.


## Exploration of the dataset
Before starting, a brief preliminary analysis of our set and a preprocessing of the data is going to be done.
```{r, message=FALSE , warning=0}
missmap(beer_reviews,col=c("blue","red"),legend=TRUE)
```

With this graph we observe that the variable *beer_abv* has some missing data (NA), but the rest of the variables are complete. As we have too many variables to visualize, let's make a summary:
```{r, message=FALSE , warning=0}
summary(beer_reviews)
```

A priori, it does not seem that we have errors derived from counting, or radically different data within the set. We note that, the variables that give us information about the users' opinion about the beers are : **review_overall** ,**review_aroma**, **review_appearance**, **review_palate**, **review_taste**. All are continuous variables that take values in the interval [0,5].

Since these are the variables that provide us with the most information, we can perform a correlation analysis between them:
```{r, message=FALSE , warning=0}
beer_analysis <- beer_reviews[,c("review_overall" ,"review_aroma", "review_appearance", "review_palate", "review_taste")]
corPlot(beer_analysis, cex = 1.2, tl.cex = 0.00001,addCoef.col = 1,cl.cex = 0.5)
```
 
  As we can see, they all have a positive correlation. In addition the review_overall variable is strongly correlated with the others, which makes sense, as it is calculated based on the others.

Finally we observe if there are duplicate rows
```{r, message=FALSE , warning=0}
summary(duplicated(beer_reviews))
```

## Debugging the dataset

Since we are not finding duplicate data or values that are NA completely, we are not going to delete any observations. We are going to change the **review_time** variable to date format:
```{r, message=FALSE , warning=0}
mydates<-beer_reviews$review_time
class(mydates) = c('POSIXt','POSIXct')
beer_reviews$review_time<-mydates
summary(beer_reviews$review_time)
```

# Which beer to choose and based on what criteria?

To choose the 3 best beers, I would take into account 2 criteria: 

- **Criterion 1**: Sufficient number of reviews. For example >= 15 reviews. For this we will work with the variable *beer_beerid*.
- **Criterion 2**:The highest average overall rating (*review_overall*).

To establish the first criterion we can perform the following filtering:

```{r, message=FALSE , warning=0}
beer_reviews$beer_beerid<-factor(beer_reviews$beer_beerid) # We transform it into a factor to work better

group_mean<-beer_reviews[ , .(means = mean(review_overall)), by = beer_beerid]
total<-beer_reviews[ , .N, by = beer_beerid]
beers_comparison<-cbind(group_mean,total[,c("N")])
#setnames(beers_comparison, old, new)

beers_comparison<-beers_comparison[N>=15,] # Criterion 1
```

We can see the frequency distribution of the resulting variable by number of observations:
```{r, message=FALSE , warning=0}
pl <- ggplot(beers_comparison, aes(x=means))
pl +  geom_histogram(binwidth = 0.2, col='black', fill='blue', alpha=0.4) + ggtitle('Frequency distribution of the variable review_overall')
```

```{r, message=FALSE , warning=0}
setorder(beers_comparison, -means) # Criterion 2
datatable(beers_comparison)
```

The *means* object contains the average number of reviews per beer, while the *total* object contains the number of reviews per beer. *beers_comparison* collects both information in the same data frame.

We observe that the beers have a representative number of reviews to be able to conclude that they are the best on the basis of this criterion. 

```{r, message=FALSE , warning=0}
ids_comparison<-apply(beers_comparison[1:3,c("beer_beerid")],1, as.numeric) # Ids we are going to search in the main dataset

unique(beer_reviews[beer_beerid==ids_comparison[1],c("beer_name")])
unique(beer_reviews[beer_beerid==ids_comparison[2],c("beer_name")])
unique(beer_reviews[beer_beerid==ids_comparison[3],c("beer_name")])


```
Therefore, the best beers based on this criterion are **Rare D.O.S.** , **Dirty Horse** and **Southampton Berliner Weisse**.

# Recommendation based on aroma and appearance

We will perform a similar procedure, but changing Criterion 2 (*review_overall*) to *review_arome* and *review_appearance*.

```{r, message=FALSE , warning=0}
beer_reviews$beer_beerid<-factor(beer_reviews$beer_beerid) # We transform it into a factor to work better

aroma_mean<-beer_reviews[ , .(aroma_mean = mean(review_aroma)), by = beer_beerid] # Average per aroma of each beer
app_mean<-beer_reviews[ , .(app_mean = mean(review_appearance)), by = beer_beerid] # Average beer per appearance
total<-beer_reviews[ , .N, by = beer_beerid]
beers_comparison<-cbind(aroma_mean,app_mean[,c("app_mean")],total[,c("N")])
#setnames(beers_comparison, old, new)
beers_comparison<-beers_comparison[N>=15,] # Criterion 1
```

In this case, as we would have to establish a "weighting" or importance to each of the two averages, what we will do is simply add both averages by *review_arome* and *review_appearance*, and then order them as in the previous point:

```{r, message=FALSE , warning=0}
beers_comparison$means <- beers_comparison[,c("aroma_mean")] + beers_comparison[,c("app_mean")]
```

We can see a representation of the resulting distribution
```{r, message=FALSE , warning=0}
pl <- ggplot(beers_comparison, aes(x=means))
pl +  geom_histogram(binwidth = 0.4, col='black', fill='blue', alpha=0.4) + ggtitle('DistribuciÃ³n de frecuencias de al suma de arome y appearance')
```

```{r, message=FALSE , warning=0}
setorder(beers_comparison, -means) # Criterion 2
datatable(head(beers_comparison))
```

We search for the names as in the previous section, to answer the question:
```{r, message=FALSE , warning=0}
ids_comparison<-apply(beers_comparison[1,c("beer_beerid")],1, as.numeric) # Ids we are going to search in the main dataset

datatable(unique(beer_reviews[beer_beerid==ids_comparison[1],c("beer_name")]))

```

Therefore, and according to the criteria applied, if what you like most is the aroma and appearance, I would recommend the **M Belgian-Style Barleywine** beer.

# Classification and classification characteristics 

As classification ideas we will provide the following:

- Classification by manufacturer:
  + Popularity
  + Rating 
  + Trend
  
- Classification by style:
  + Popularity
  + Rating
  + Trend
  
- Ranking by % of alcohol.
  
The variables we are going to take as reference for the classification are **review_overall**, **review_time** , **brewery_id** and **beer_style** and **beer_abv**.

At the **trend*** point we will choose the data from the last year of the dataset, and see which one has the most reviews, which will not indicate the trend or the beer that is the most fashionable at the moment. In our case we will choose the beers that were the most fashionable during 2011, up to November, which is as far as we have data available.

```{r, message=FALSE , warning=0}
reviews_2012 <- beer_reviews[review_time>'2011-01-01',]
reviews_2012 <- reviews_2012[review_time<'2012-01-01',]
```

## Classification by manufacturer
```{r, message=FALSE , warning=0}
# We create the variables necessary for the classification
beer_reviews[ , ratings_brewerly := .N, by = brewery_id]
beer_reviews[ , mean_brewery := mean(review_overall), by = brewery_id]
brewery_info<-unique(beer_reviews[,c("brewery_id","brewery_name","ratings_brewerly","mean_brewery")])
```

### Popularity
```{r, message=FALSE , warning=0}
datatable(setorder(brewery_info, -ratings_brewerly)) 
```

### Rating
```{r, message=FALSE , warning=0}
brewery_info2<-brewery_info[ratings_brewerly>=15,] # We choose the ones with enough comments
datatable(setorder(brewery_info2, -mean_brewery)) 
```
### Trend
```{r, message=FALSE , warning=0}
reviews_2012[ , ratings_brewerly2012 := .N, by = brewery_id]
tendencia2012<-unique(reviews_2012[,c("brewery_id","brewery_name","ratings_brewerly2012")])
datatable(setorder(tendencia2012, -ratings_brewerly2012)) # Brewery trend during 2012
```

## Classification by style
```{r, message=FALSE , warning=0}
beer_reviews[ , rating_style := .N, by = beer_style]
beer_reviews[ , mean_style := mean(review_overall), by = beer_style]
style_info<-unique(beer_reviews[,c("beer_style","rating_style","mean_style")])
```
### Popularity
```{r, message=FALSE , warning=0}
datatable(setorder(style_info, -rating_style))
```

### Rating
```{r, message=FALSE , warning=0}
style_info2<-style_info[rating_style>=15,] # We choose the ones with enough comments
datatable(setorder(style_info2, -mean_style))
```
### Trend
```{r, message=FALSE , warning=0}
reviews_2012[ , ratings_style2012 := .N, by = beer_style]
tendencia2012<-unique(reviews_2012[,c("beer_style","ratings_style2012")])
datatable(setorder(tendencia2012, -ratings_style2012)) # Brewery trend during 2012
```
## Classification by % alcohol

To make this classification correctly, we would need the opinion of an expert brewer. If we make it our own, we can base it on its frequency distribution:
```{r, message=FALSE , warning=0}
beers_info<-unique(beer_reviews[,"beer_beerid","beer_abv"])
pl <- ggplot(beers_info, aes(x=beer_abv))
pl +  geom_histogram(binwidth = 0.8, col='black', fill='blue', alpha=0.4) + ggtitle('Frequency distribution of alcohol by beer')
```

In this case, we will apply a simple criterion of non-alcoholic beers, mild (0-3), normal (3-6) and strong (6-10) and very strong (>10). It would also be interesting to apply unsupervised learning methods such as K-means to make groupings of this variable.

```{r, message=FALSE , warning=0}

beers_info_freq <- cut(beers_info$beer_abv, breaks = c(0,0.1,3,6,10, Inf), 
             labels = c('non', 'mild', 'normal','strong','very strong'), right = FALSE)

summary(beers_info_freq)
```

This would be the classification of the different beers in our dataset.  We will store this information in the dataset.

```{r, message=FALSE , warning=0}

beer_reviews$beer_abv <- cut(beer_reviews$beer_abv, breaks = c(0,0.1,3,6,10, Inf), 
             labels = c('non', 'mild', 'normal','strong','very strong'), right = FALSE)

summary(beer_reviews$beer_abv)
```

# Influence of the factors (arome, taste, appearance, palette) in determining the overall quality.

In this section, we are going to plan a GLM model to see the influence of the different ratings on the overall rating.

## GLM hypothesis testing
We have continuous response variables, so we already know that the **continuity hypothesis** of the response variables is satisfied.

```{r, message=FALSE , warning=0}
modelo1 = glm(formula = review_overall~ +review_overall+review_aroma+review_appearance+review_palate+review_taste, data = beer_reviews)

plot(modelo1, col = "blue")
```
- In the Residuals vs fitted plot we see that we do not have strong influence points.
- We have no apparent homoscedasticity problems.
- The hypothesis of normality of the residuals is fulfilled.
- Where we might find a possible problem is in the nonlinearity of the residuals, 

## Model fit and conclusions
Based on the above, we are able to propose a GLM, taking as independent variable the **review_overall ** variable:

```{r, message=FALSE , warning=0}
summary(modelo1)
#end
```

Based on this model, we can conclude:

- All ratings positively affect the overall rating.

- All variables are significant in explaining the overall rating.

- The variable **review_taste**, and therefore **the taste of a beer, has the greatest influence on the overall rating**.

